{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title\n",
    "MCMC from Scratch for Neural Networks\n",
    "\n",
    "## Description :\n",
    "The aim of this exercise is to perform Monte Carlo Markov Chain (MCMC) from scratch for a simple neural network.\n",
    "\n",
    "On completing the exercise you should be able to see a distribution similar to the following. One for each network parameter:\n",
    "\n",
    "<img src=\"../fig/fig2.png\" style=\"width: 500px;\">\n",
    "\n",
    "## Instructions:\n",
    "- Read the data file backprop.csv and set the predictor and response variables.\n",
    "- Create 3 lists to store the weights and bias (i.e. the network parameters) and initialize the parameter values.\n",
    "- Define a function `get_log_prior` to compute the prior value given the network parameter values. \n",
    "- Compute the likelihood, prior and posterior for the initial parameter values.\n",
    "- For a selected number of sampling \"epochs\":\n",
    "    - Compute new weights and bias.\n",
    "    - Compute the corresponding likelihood, prior and posterior.\n",
    "    - Compute the exponential ratio of the current and previous posterior.\n",
    "    - Based on the ratio, select or reject the new parameter values.\n",
    "- Choose a burn rate.\n",
    "- Plot the histogram of the weights and bias.\n",
    "\n",
    "## Hints: \n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.log.html\" target=\"_blank\">np.log()</a> Computes the natural logarithm, element-wise.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.exp.html?highlight=exp#numpy.exp\" target=\"_blank\">np.exp()</a> Calculates the exponential of all elements in the input array.\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/reshape\" target=\"_blank\">tf.reshape()</a> Reshapes a tensor.\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression#sklearn.linear_model.LinearRegression.fit\" target=\"_blank\">.fit()</a> Fits the linear model to the data.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html?highlight=random%20normal#numpy.random.normal\" target=\"_blank\">np.random.normal()</a> Draw random samples from a normal (Gaussian) distribution.\n",
    "\n",
    "<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\" target=\"_blank\">norm.pdf()</a> A normal continuous random variable.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.sum.html?highlight=sum\" target=\"_blank\">np.sum()</a> Sum of array elements over a given axis.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html?highlight=random%20uniform\" target=\"_blank\">np.random.uniform()</a> Draw samples from a uniform distribution.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.zeros.html\" target=\"_blank\">np.zeros()</a> Return a new array of given shape and type, filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from random import sample\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "dtype = 'float32'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file \"backprop.csv\"\n",
    "df = pd.read_csv(\"backprop.csv\")\n",
    "\n",
    "# Take a quick look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictor and response data\n",
    "X_data = df.iloc[:,0]\n",
    "y_data = df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper code to visualize the data \n",
    "plt.figure(figsize=(4,6))\n",
    "plt.scatter(X_data, y_data,color='g' ,s = 20, alpha = 0.5, label='sample data')\n",
    "\n",
    "plt.xlabel('X',fontsize=14); \n",
    "plt.ylabel('Y',fontsize=14)\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.0, wspace=0.2, hspace=0.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predictor and response variables to tensor data\n",
    "x = tf.convert_to_tensor(X_data)\n",
    "x = tf.reshape(x,(-1,1))\n",
    "y = tf.convert_to_tensor(y_data)\n",
    "y = tf.reshape(y, (-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to define the neural network model\n",
    "# The network has 2 hidden nodes and one output node\n",
    "# We use sin activation for this exercise\n",
    "# The network has a total of 5 parameters - 4 weights and one bias for the output\n",
    "\n",
    "def basic_nn(w0,w1,b1,x=x):\n",
    "    h1 = tf.matmul(x,w0)\n",
    "    a1 = tf.math.sin(h1)\n",
    "    h2 = tf.matmul(a1,w1) + b1\n",
    "    y = tf.math.sin(h2)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 3 empty lists to store the accepted network parameters\n",
    "\n",
    "# The weights0_list will contain 2 weights that connects the input\n",
    "# to the hidden layer\n",
    "weights0_list = []\n",
    "\n",
    "# The weights1_list will contain 2 weights that connects the hidden\n",
    "# nodes to the output\n",
    "weights1_list = []\n",
    "\n",
    "# The bias_list will hold the bias added to the output of the hidden nodes\n",
    "bias_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the input to hidden weights randomly from a normal distribution \n",
    "# with mean=(1,1) and standard deviation=(1,1)\n",
    "# Reshape the values to shape (1,2)\n",
    "weights0 = tf.reshape(np.random.normal(loc=(-0.4,12),scale=(0.1,0.1), size=(1,2)), shape=(1,2))\n",
    "\n",
    "# Initialize the hidden to output weights randomly from a normal distribution \n",
    "# with mean=(-0.4,12) and standard deviation=(0.1,0.1)\n",
    "# Reshape the values to shape (2,1)\n",
    "weights1 = tf.reshape(np.random.normal(loc=(0.6, 0),scale=(0.1)), shape=(2,1))\n",
    "\n",
    "# Initialize the bias randomly from a normal distribution \n",
    "# with mean=1 and standard deviation=1\n",
    "bias = np.random.normal(loc=2.5, scale=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the prior given the network parameters\n",
    "# NOTE - All the computations are done in the log space so \n",
    "# that the numbers are managable.\n",
    "\n",
    "def get_log_prior(weights0,weights1, bias):\n",
    "\n",
    "    # Initialize a numpy array of zeros with shape 2,1\n",
    "    prior_w0 = ___\n",
    "    \n",
    "    # Find the probability of the first weight given the normal PDF with mean =1 and std=1\n",
    "    # Take the log of this value\n",
    "    prior_w0[0] = np.log(norm.pdf(weights0[0][0],-0.4, 0.1))\n",
    "    \n",
    "    # Find the probability of the second weight given the normal PDF with mean =1 and std=1\n",
    "    # Take the log of this value\n",
    "    prior_w0[1] = np.log(___)\n",
    "\n",
    "    # Initialize a numpy array of zeros with shape 2,1\n",
    "    prior_w1 = ___  \n",
    "    \n",
    "    # Find the probability of the third weight given the normal PDF with mean =0.6 and std=0.1\n",
    "    # Take the log of this value\n",
    "    prior_w1[0] = np.log(___)\n",
    "    \n",
    "    # Find the probability of the first weight given the normal PDF with mean =0 and std=0.1\n",
    "    # Take the log of this value\n",
    "    prior_w1[1] = np.log(___)\n",
    "\n",
    "    # Find the probability of the bias given the normal PDF with mean=2.5 and std=0.1\n",
    "    # Take the log of this value\n",
    "    prior_bias = np.log(___)\n",
    "    \n",
    "    # Compute the prior as the sum of the previously computed priors\n",
    "    log_prior = ___\n",
    "  \n",
    "    # Return the prior value\n",
    "    return log_prior\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prior of the initial network parameters by calling the get_log_prior function\n",
    "log_prior = ___\n",
    "\n",
    "# Get the network predictions by calling the basic_nn function\n",
    "ypred = ___\n",
    "\n",
    "# Compute the -ve log likelihood  given the true y and predicted y\n",
    "log_likelihood =  -np.sum(((y-ypred)**2))\n",
    "\n",
    "# Compute the posterior as the sum of the likelihood and prior\n",
    "posterior = ___\n",
    "\n",
    "# Save the current posterior value as prev_posterior for comparision later\n",
    "prev_posterior = ___\n",
    "\n",
    "# Append weights0 to the weights0_list\n",
    "weights0_list.append(weights0)\n",
    "\n",
    "# Append weights1 to the weights1_list\n",
    "weights1_list.append(weights1)\n",
    "\n",
    "# Append bias to the bias_list\n",
    "bias_list.append(bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of sampling \"epochs\". Set it to atleast 10000\n",
    "epochs = ___\n",
    "\n",
    "# Loop over the range of sampling \"epochs\"\n",
    "for i in range(epochs):\n",
    "    if i%5000==0:\n",
    "        print(\"EPOCH: \",i)\n",
    "\n",
    "    # Get the candidate input to hidden weights randomly from a normal distribution \n",
    "    # with mean as the last element added to weights0_list and standard deviation=(0.1,0.1)\n",
    "    # Reshape the values to shape (1,2)\n",
    "    weights0 = tf.reshape(np.random.normal(loc=weights0_list[-1],scale=(0.1, 0.1)), shape=(1,2))\n",
    "\n",
    "    # Get the candidate hidden to output weights randomly from a normal distribution \n",
    "    # with mean as the last element added to weights1_list and standard deviation=1\n",
    "    # Reshape the values to shape (2,1)\n",
    "    weights1 = tf.reshape(___, shape=(2,1))\n",
    "\n",
    "    # Get the candidate bias randomly from a normal distribution \n",
    "    # with mean as the last element added to bias_list and standard deviation=1\n",
    "    bias = ___\n",
    "\n",
    "    # Get the prior values for the candidate values by calling the get_log_prior function\n",
    "    log_prior = ___\n",
    "\n",
    "    # Get the network predictions by calling the basic_nn function with the candidate values\n",
    "    ypred = ___\n",
    "\n",
    "    # Compute P(data|w) i.e. the log-likelihood given the true y and predicted y\n",
    "    log_likelihood = ___\n",
    "\n",
    "    # To compute the posterior given the likelihood and prior\n",
    "    # The posterior is the sum of the likelihood and prior\n",
    "    posterior = ___\n",
    "\n",
    "    # Compute the the exponential of the ratio of the posterior given its previous value\n",
    "    exp_ratio = ___\n",
    "\n",
    "    # If the ratio is greater than or equal to 1 then accept the candidate values in this case\n",
    "    if exp_ratio>=1:\n",
    "\n",
    "        # Append the candidate values to the weights and bias list\n",
    "        weights0_list.append(weights0)\n",
    "        weights1_list.append(weights1)\n",
    "        bias_list.append(bias)\n",
    "\n",
    "        # Save the accepted posterior as the previous posterior\n",
    "        prev_posterior = posterior\n",
    "\n",
    "    # If the ratio is less than 1 then get a random value between 0 and 1\n",
    "    else:\n",
    "        coin = ___\n",
    "\n",
    "        # Set a threshold value\n",
    "        threshold = 0.98\n",
    "        \n",
    "        # Check if the random value is higher than the threshold\n",
    "        # Append the candidate values to the list and update the previous posterior\n",
    "        if coin > threshold:\n",
    "            weights0_list.append(weights0)\n",
    "            weights1_list.append(weights1)\n",
    "            bias_list.append(bias)\n",
    "            prev_posterior = posterior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of data points to consider after the beta list has been populated\n",
    "burn_rate = int(len(bias_list)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper code to plot the distribution of network parameter\n",
    "fig, ax = plt.subplots(5,2, figsize=(15,15))\n",
    "col1 = \"#B2D7D0\"\n",
    "col2 = \"#EFAEA4\"\n",
    "fs = 12\n",
    "\n",
    "with plt.xkcd(scale=0.01):\n",
    "  ax[0][0].hist(np.array(weights0_list)[:,0,0], color=col1,linewidth=1.2,edgecolor='black')\n",
    "  ax[0][0].set_xlabel(\"Weight 1\")\n",
    "  ax[0][0].set_ylabel(\"Frequency\")\n",
    "\n",
    "\n",
    "  ax[0][1].plot(np.array(weights0_list)[:,0,0], color=col2)\n",
    "  ax[0][1].set_xlabel(\"Weight 1\")\n",
    "  ax[0][1].set_title(\"CHAIN\", fontsize=14)\n",
    "\n",
    "  ax[1][0].hist(np.array(weights0_list)[:,0,1], color=col1,linewidth=1.2,edgecolor='black')\n",
    "  ax[1][0].set_xlabel(\"Weight 2\")\n",
    "  ax[1][0].set_ylabel(\"Frequency\")\n",
    "\n",
    "  ax[1][1].plot(np.array(weights0_list)[:,0,1], color=col2)\n",
    "  ax[1][1].set_xlabel(\"Weight 2\")\n",
    "\n",
    "\n",
    "  ax[2][0].hist(np.array(weights1_list)[:,0,0], color=col1,linewidth=1.2,edgecolor='black')\n",
    "  ax[2][0].set_xlabel(\"Weight 3\")\n",
    "  ax[2][0].set_ylabel(\"Frequency\")\n",
    "\n",
    "  ax[2][1].plot(np.array(weights1_list)[:,0,0], color=col2)\n",
    "  ax[2][1].set_xlabel(\"Weight 3\")\n",
    "\n",
    "\n",
    "  ax[3][0].hist(np.array(weights1_list)[:,1,0], color=col1,linewidth=1.2,edgecolor='black')\n",
    "  ax[3][0].set_xlabel(\"Weight 4\")\n",
    "  ax[3][0].set_ylabel(\"Frequency\")\n",
    "\n",
    "  ax[3][1].plot(np.array(weights1_list)[:,1,0], color=col2)\n",
    "  ax[3][1].set_xlabel(\"Weight 4\")\n",
    "\n",
    "  ax[4][0].hist(np.array(bias_list), color=col1,linewidth=1.2,edgecolor='black')\n",
    "  ax[4][0].set_xlabel(\"Bias\")\n",
    "  ax[4][0].set_ylabel(\"Frequency\")\n",
    "\n",
    "  ax[4][1].plot(np.array(bias_list), color=col2)\n",
    "  ax[4][1].set_xlabel(\"Bias\")\n",
    "\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ Go back and change the mean and standard deviation of weights1 while intializing to 0 and 1 respectively. What change do you notice in the result distribution?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow1) ###\n",
    "# Type your answer in the space given below\n",
    "answer1 = '___'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ How is the distribution affected if mean and standard deviation of prior_w1[0] and prior_w1[0] are set to 0 and 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow2) ###\n",
    "# Type your answer in the space given below\n",
    "answer2 = '___'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ For each network parameter, what affect does increase in scale of the prior from 0.1 to 10 expect to bring out, given you start from a prior that is very close to the true value?\n",
    "\n",
    "#### A. With a wider range of possible values, the parameters would converge to the true values faster.\n",
    "#### B. The prior is a constant, and hence does not affect the the parameter convergence.\n",
    "#### C. The parameters will take longer to converge to their true values as the values bounce around more.\n",
    "#### D. The parameter only depends on the mean and previous prior, not the standard deviation. Hence, there would be no affect with a change in the standard devidation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow3) ###\n",
    "# Submit an answer choice as a string below (eg. if you choose option C, put 'C')\n",
    "answer3 = '___'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper code to visualize the prediction by taking the mean of the network parameters\n",
    "wl = np.array(weights0_list[burn_rate:])\n",
    "wl2 = np.array(weights1_list[burn_rate:])\n",
    "bi = np.array(bias_list[burn_rate:])\n",
    "\n",
    "# Take the mean of the model parameters\n",
    "w0 = np.mean(wl[:,0,:], axis=0).reshape(1,2)\n",
    "w1 = np.mean(wl2[:,:,0], axis=0)\n",
    "w1 = tf.reshape(tf.cast(w1, dtype='float32'), shape=(2,1))\n",
    "b1 = np.mean(bi)\n",
    "\n",
    "# Get the network prediction\n",
    "h1 = tf.matmul(tf.cast(x, dtype='float32'), w0)\n",
    "a1 = tf.math.sin(h1)\n",
    "h2 = tf.matmul(a1,w1) + b1\n",
    "y_pred = tf.math.sin(h2)\n",
    "\n",
    "# Plot the true data and model prediction\n",
    "plt.plot(X_data, y_data, 'b+', label=\"True Data\")\n",
    "plt.plot(X_data, y_pred, 'ro', label = \"Prediction\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}