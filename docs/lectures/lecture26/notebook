{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title\n",
    "Introduction to Autoencoders using MNIST\n",
    "\n",
    "## Description :\n",
    "The goal of the exercise is to use an autoencoder to first compress hand-written digit images from the MNIST dataset down to lower-dimensional representations and then expand them back to the original images.\n",
    "\n",
    "Your final output will look similar to the image below: \n",
    "\n",
    "<img src=\"../fig/fig1.png\" style=\"width: 500px;\">\n",
    "\n",
    "## Instructions:\n",
    "- Load the MNIST dataset with the `mnist.load_data()` function provided by keras. Load the images in two separate lists, `x_train` and `x_test`.\n",
    "- Create the first part of the autoencoder - the encoder model.\n",
    "    - The encoder model compresses the input image down to a lower dimensional latent space\n",
    "- Next create the 2nd half of the autoencoder - the decoder.\n",
    "    - The decoder expands an image representation in the latent space back to the full dimensions of the original input image.\n",
    "- Normalize your data by dividing each pixel by 255.\n",
    "- Finally, we combine the encoder and decoder into the autoencoder.\n",
    "- The autoencoder shrinks the image down to the latent space representation and then expands it again to the original dimensions.\n",
    "- Visualize the model predictions on the test set after every epoch using the helper code given.\n",
    "- You can experiment with the different `latent_size`, `layer_size` and `regularization`.\n",
    "\n",
    "## Hints: \n",
    "\n",
    "More on Keras Functional API <a href=\"https://www.tensorflow.org/guide/keras/functional\" target=\"_blank\">here</a>. \n",
    "\n",
    "<a href=\"https://keras.io/guides/sequential_model/\" target=\"_blank\">keras.compile()</a> Compiles the layers into a network.\n",
    "\n",
    "<a href=\"https://keras.io/guides/sequential_model/\" target=\"_blank\">keras.Sequential()</a> Models a sequential neural network.\n",
    "\n",
    "<a href=\"https://keras.io/api/layers/core_layers/dense/\" target=\"_blank\">keras.Dense()</a> A regular densely-connected NN layer.\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten\" target=\"_blank\">layers.Flatten()</a> Flattens the input. Does not affect the batch size.\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Input\" target=\"_blank\">tf.keras.Input()</a> Used to instantiate a Keras tensor.\n",
    "\n",
    "**NOTE:** To keep things simple we will use dense layers, so no convolutions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Reshape\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display \n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_normalize) ###\n",
    "# First we load in the MNIST dataset.\n",
    "\n",
    "# Do not fill in the blank space\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "\n",
    "# We will only take 4000 data points from the original dataset to demonstrate the autoencoders\n",
    "sample_size = 4000 \n",
    "x_train = x_train[:sample_size]\n",
    "x_test = x_test[:sample_size]\n",
    "\n",
    "# We normalize the pixel data (i.e divide by 255)\n",
    "\n",
    "x_train = ___\n",
    "x_test = ___\n",
    "\n",
    "# We print image dimensions to confirm \n",
    "print(f'image shape: {x_train[0].shape} and random pixel value is {x_train[0][20][10]}')\n",
    "\n",
    "# We also plot example image from x_train\n",
    "plt.imshow(x_train[0], cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_model_encoder) ###\n",
    "# Now we create the encoder model to take compress each image down to a lower dimensional latent space.\n",
    "\n",
    "# pick a size for the latent dimension like 32\n",
    "latent_size = ___\n",
    "\n",
    "# Note how sequential models can also be passed a list of layers\n",
    "\n",
    "# This can be more concise than using add()\n",
    "model_1 = models.Sequential(name='Encoder')\n",
    "\n",
    "# add a flatten layer to convert image of size (28,28) to 784\n",
    "# don't forget to include the `input_shape` argument\n",
    "model_1.add(___)\n",
    "\n",
    "# add a dense layer with 128 neurons\n",
    "model_1.add(___)\n",
    "\n",
    "# add another dense layer with 64 neurons\n",
    "model_1.add(___)\n",
    "\n",
    "# Finally add the last dense layer with latent_size number of neurons\n",
    "model_1.add(___)\n",
    "\n",
    "# Take a quick look at the model summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_model_decoder) ###\n",
    "# Now we create the decoder model to take compress each image down to a lower dimensional latent space.\n",
    "model_2 = models.Sequential(name='Decoder')\n",
    "\n",
    "# add a dense layer with 64 neurons\n",
    "model_2.add(___)\n",
    "\n",
    "# add a dense layer with 128 neurons\n",
    "model_2.add(___)\n",
    "\n",
    "# add a dense layer with 784 neurons and especially choose an appropriate activation function\n",
    "model_2.add(___)\n",
    "\n",
    "# finally reshape it back to size 28,28\n",
    "model_2.add(___)\n",
    "\n",
    "# Take a quick look at the model summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_model_autoencoder) ###\n",
    "# To build autoencoders, we will use the keras 'functional api'\n",
    "# read more here -> https://www.tensorflow.org/guide/keras/functional\n",
    "\n",
    "# define an input of the dimension of the image\n",
    "img = Input(shape=(28,28))\n",
    "\n",
    "# Use the 'encoder' i.e model_1 from above to get a variable `latent_vector`\n",
    "latent_vector = model_1(___)\n",
    "\n",
    "# Use the 'decoder' i.e model_2 from above to get the output variable\n",
    "output = model_2(___)\n",
    "\n",
    "\n",
    "# using functional api to define autoencoder model\n",
    "autoencoder = Model(inputs = ___, outputs = ___)\n",
    "\n",
    "# choose an appropriate loss function for 'reconstruction error' and optimizer = nadam\n",
    "autoencoder.compile(___)\n",
    "\n",
    "# Take a quick look at the model summary\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can train for 10 or more epochs to see how well our autoencoder model performs\n",
    "epochs = 10\n",
    "\n",
    "for i in range(epochs+1):\n",
    "# Note: epoch 0 is before any fitting\n",
    "    fig, axs = plt.subplots(1, 2,figsize = (8,4))\n",
    "    sample_x = x_test[np.random.choice(x_test.shape[0])]\n",
    "    axs[0].imshow(sample_x,cmap = \"gray\")\n",
    "    axs[0].set_title('Test image',fontsize = 16)\n",
    "    axs[1].imshow(autoencoder.predict(sample_x.reshape(1,28,28))[0],cmap = \"gray\")\n",
    "    axs[1].set_title('Autoencoder Prediction',fontsize = 16);\n",
    "    fig.suptitle(f'Autoencoder recreation after epoch number {i}',fontsize =14)\n",
    "    plt.show()\n",
    "    \n",
    "    # specify predictors and targets for train and validation and train for an epoch\n",
    "    \n",
    "    autoencoder.fit(x=x_train,\n",
    "                y=x_train,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mindchow üç≤\n",
    "\n",
    "Go back and change the `latent_space` dimension to a lower value like 2. Does your autoencoder's reconstructions become better or worse? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
