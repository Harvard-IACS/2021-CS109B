{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title \n",
    "Exercise: Attention\n",
    "\n",
    "## Description :\n",
    "In this exercise, you will implement an Attention mechanism. We load three encoder hidden states into `enc_states`, and 1 decoder hidden state into `dec_state`. Your task is to compute the final `context_vector`.\n",
    "\n",
    "That is, you should calculate an Attention score for every encoder hidden state, exponentiate these, then normalize them so they sum to 1. These are your Attention weights. Then, produce a context vector by multiplying each Attention weight by its corresponding encoder hidden state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"red\">**REMINDER**</font>: After running every cell, be sure to auto-grade your work by clicking 'Mark' in the lower-right corner. Otherwise, no credit will be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports useful libraries\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">YOU DO NOT NEED TO EDIT THE CELL BELOW</font>\n",
    "\n",
    "The follow code loads three encoder states into the dictionary `enc_states`, whereby the keys are 0, 1, and 2, and their respective values are lists of 50 floats (representing each hidden state). The code also populates a single list of floats, `dec_state`, which contains 50 floats (representing the hidden state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes we're passing in several enc states but only 1 dec states\n",
    "def load_hidden_states(filename):\n",
    "    enc_states = {}\n",
    "    dec_state = []\n",
    "    \n",
    "    f = open(filename)\n",
    "    for line in f.readlines():\n",
    "        model, num = line.split()[0].split(\"_\")\n",
    "        if model == \"enc\":\n",
    "            enc_states[int(num)] = [float(t) for t in line.split(\" \")[1:]]\n",
    "        else:\n",
    "            dec_state = [float(t) for t in line.split(\" \")[1:]]\n",
    "    return enc_states, dec_state\n",
    "\n",
    "enc_states, dec_state = load_hidden_states(\"hidden_states.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">YOU DO NOT NEED TO EDIT THE CELL BELOW</font>\n",
    "\n",
    "The follow code simply computes the attention score as the dot-product between the two passed-in embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the attention score as the dot product\n",
    "def calculate_attention_score(v1, v2):\n",
    "    return sum(a*b for a, b in zip(v1, v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, populate `attention_scores` with the _exponentiated_ attention scores: $e^{(\\text{score(enc_i, dec_j)})}$. The main aspect to figure out is which hidden states to pass to `calculate_attention_score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_a) ###\n",
    "attention_scores = []\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, simply _normalize_ each of the exponentiated scores and store them in `attention_weights`. They should sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_b) ###\n",
    "attention_weights = []\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, create the final context vector `context_vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_c) ###\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "context_vector = # YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
