{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title :\n",
    "RNN from scratch\n",
    "\n",
    "## Description :\n",
    "The aim of this exercise is to understand what happens within an RNN unit that is wrapped within the tensorflow.keras.layers.SimpleRNN\n",
    "\n",
    "The idea is to write a Recurrent Neural Network from scratch that generates names of dinosaurs by training on the existing names character-wise.\n",
    "\n",
    "## Instructions:\n",
    "- Read the file `dino.txt` and convert all the names in the files to lowercase.\n",
    "- Save the names in the file as a list.\n",
    "- Get the number of words in the file and the vocabulary size which is equal to the number of alphabets plus the newline character.\n",
    "- Define a dictionary `char_to_ix`  where the key is the sorted vocabulary and the value is the integer value assigned to it.\n",
    "- Define a dictionary `ix_to_char`  where the key is the integer value assigned to the unique vocabulary and the value is the sorted vocabulary.\n",
    "- To get the model parameters (weights and biases) call the get_weights function twice once by:\n",
    "    - Setting the `random` parameter as 1 to get random weights\n",
    "    - Setting the `random` parameter as 0 to get the trained weights by specifying the number of iterations.\n",
    "- Define a function `rnn_model` that takes in the network parameters and outputs the generated dinosaur name based on the instructions in the scaffold.\n",
    "\n",
    "## Hints:\n",
    "\n",
    "$$h_t\\ =\\ \\tanh\\left(\\ Uh_{t-1}\\ +\\ Vx_t\\ +\\ \\beta_1\\right)$$\n",
    "\n",
    "$$Y_{t\\ }\\ =\\ \\sigma\\left(Wh_t\\ +\\ \\beta_2\\right)$$\n",
    "\n",
    "\n",
    "<a href=\"https://docs.python.org/3/library/functions.html#sorted\" target=\"_blank\">sorted()</a> Return a new sorted list from the items in iterable.\n",
    "\n",
    "<a href=\"https://book.pythontips.com/en/latest/enumerate.html\" target=\"_blank\">enumerate()</a> Allows to loop over something and have an automatic counter.\n",
    "\n",
    "<a href=\"https://docs.python.org/3/library/stdtypes.html?highlight=lower#str.lower\" target=\"_blank\">lower()</a> Return a copy of the string with all the cased characters converted to lowercase.\n",
    "\n",
    "<a href=\"https://docs.python.org/3/library/stdtypes.html?highlight=strip#str.strip\" target=\"_blank\">strip()</a> Return a copy of the string with the leading and trailing characters removed.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/random/generated/numpy.random.shuffle.html\" target=\"_blank\">np.random.shuffle()</a> Modify a sequence in-place by shuffling its contents.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.zeros.html?highlight=zeros#numpy.zeros\" target=\"_blank\">np.zeros()</a> Return a new array of given shape and type, filled with zeros.\n",
    "\n",
    "<a href=\"https://docs.python.org/3/library/stdtypes.html?highlight=join#str.join\" target=\"_blank\">join()</a> Return a string which is the concatenation of the strings in iterable.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.tanh.html?highlight=tanh#numpy.tanh\" target=\"_blank\">np.tanh()</a> Compute hyperbolic tangent element-wise.\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.dot.html?highlight=dot#numpy.dot\" target=\"_blank\">np.dot()</a> Returns the dot product of two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "import numpy as np\n",
    "from helper import softmax, get_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the next set of characters which forms the dinosaur name\n",
    "def rnn_model(parameters, char_to_ix):\n",
    "\n",
    "    # Get the weights and biases from the parameters dictionary\n",
    "    U, V, W = parameters['U'], parameters['V'], parameters['W']\n",
    "    beta1, beta2 = parameters['beta1'], parameters['beta2']\n",
    "\n",
    "    # Get the size of the vocabulary i.e. 27\n",
    "    # One for each alphabet plus the new line character\n",
    "    vocab_size = beta2.shape[0]\n",
    "\n",
    "    # Get the size of the weights\n",
    "    n_h = U.shape[1]    \n",
    "\n",
    "    # Initialize the input as an array of zeroes with size as (vocab_size,1)\n",
    "    # This one-hot encodes the input\n",
    "    x = ___\n",
    "\n",
    "    # Initialize the inital hidden state as an array of zeroes with size as (n_h,1)    \n",
    "    h_prev = ___\n",
    "\n",
    "    # Initialize a list to store the indices of the predicted characters\n",
    "    indices = []\n",
    "    \n",
    "    # Initialize an idx variable to hold the index values of the characters \n",
    "    idx = -1 \n",
    "    \n",
    "    # Initialize a counter to fix the maximum length of the predicted word\n",
    "    counter = 0\n",
    "\n",
    "    # Get the value of the new line from the char_to_ix dictionary\n",
    "    newline_character = char_to_ix['\\n']\n",
    "    \n",
    "    # Loop until the newline_character is predicted or until the max length of the word is 50\n",
    "    while (idx != newline_character and counter != 50):\n",
    "\n",
    "        # Compute the new state h of the RNN unit using the equation given in the instructions\n",
    "        h = ___\n",
    "\n",
    "        # Compute the output of the RNN unit using the equation \n",
    "        # given in the instructions using the softmax function\n",
    "        y = softmax(___)\n",
    "\n",
    "        # Get the index value of the predicted/generated character\n",
    "        # Instead of taking the argmax, we perform sampling on the probabilities \n",
    "        # got from the softmax function\n",
    "        idx = np.random.choice(list(range(vocab_size)), p=y.ravel())\n",
    "\n",
    "        # Append the index value to the indices list\n",
    "        indices.append(idx)\n",
    "        \n",
    "        # Initialize an array of with zeroes with size (vocab_size,1)\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "\n",
    "        # Set the idx position of x as 1.\n",
    "        # This will act as the output y and the next input. \n",
    "        x[idx] = 1\n",
    "        \n",
    "        # Update the previous state value with the current state\n",
    "        h_prev = ___\n",
    "        \n",
    "        # Increment the counter\n",
    "        counter+=1\n",
    "    \n",
    "    # If the counter value reaches 50 append a newline character to the indices list\n",
    "    if (counter == 50):\n",
    "        indices.append(char_to_ix['\\n'])\n",
    "    \n",
    "    # Return the list of indices\n",
    "    return indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dinos.txt file\n",
    "data = open('dinos.txt', 'r').read()\n",
    "\n",
    "# Convert the data to lower case\n",
    "data= data.lower()\n",
    "\n",
    "# Convert the file data into list\n",
    "chars = list(set(data))\n",
    "\n",
    "# Get length of the file and length of the vocabulary\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "\n",
    "# Define a dictionary with the sorted vocabulary as key and \n",
    "# value as a unique integer using enumerate\n",
    "char_to_ix = ___\n",
    "\n",
    "# Define a dictionary with the unique integers assigned to the sorted vocabulary as key\n",
    "# and value as a unique integer using enumerate\n",
    "ix_to_char = ___\n",
    "\n",
    "# Call the get_weights function to get the model weights\n",
    "# To get random weights set random=1\n",
    "# To get the trained weights specify the number of iterations and set random=0\n",
    "parameters = get_weights(num_iterations=1000, random=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the predict function defined above passing \n",
    "# the parameters dictionary, char_to_ix dictionary\n",
    "sampled_indices = rnn_model(parameters, char_to_ix)\n",
    "\n",
    "# Convert the list of indices returned by the predict function to \n",
    "# their respective characters and then join to form a word\n",
    "txt = ___\n",
    "\n",
    "# Captializing the first character\n",
    "txt = txt[0].upper() + txt[1:]  \n",
    "\n",
    "# Print the generated dinosaur name \n",
    "print('%s' % (txt, ), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ What do you observe from the generated names when the number of iterations in the get_weights function increase to 20,000 with random=0?\n",
    "\n",
    "#### A. The length of the names generated increases proportionately with the number of iterations.\n",
    "#### B. Insufficient storage because of large window size.\n",
    "#### C. The names generated are better due to longer training.\n",
    "#### D. Larger number of iterations causes the loss of the model to increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow1) ###\n",
    "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
    "answer1 = '___'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ What is the difference in the generated name from when the model is given random weights and trained weights?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow2) ###\n",
    "# Type your answer within in the quotes given\n",
    "answer2 = '___'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
